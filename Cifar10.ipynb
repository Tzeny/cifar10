{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Tzeny/cifar10/blob/master/Cifar10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "509BEESjqAt5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is my attempt at solving the Cifar10 challenge. This file is also available on GitHub: [https://github.com/Tzeny/cifar10/blob/master/Cifar10.ipynb](https://github.com/Tzeny/cifar10/blob/master/Cifar10.ipynb)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZU99-wAUrBei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "|Model architecture | Optimizer | Batch size  | Train images | Stop epoch | Test accuracy |\n",
        "|------------- |---|-------------|----|\n",
        "|2 x inception(w dr 3,36) 2 x (conv(144ft)+maxpool) flt 2 x dense (w dr) act \\[w batch normalization\\]|Adam(0.001)|128|Normalized color |~20|~93 %\n",
        "|3 x inception(w dr 3, 36,216) (conv(288ft)+maxpool) flt 2 x dense (w dr) \\[w batch normalization\\]|Adam(0.001)|128|Normalized color|65|86.37 %"
      ]
    },
    {
      "metadata": {
        "id": "mIYeok5Dp-YC",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[Google Colab ensure we have our own GPU](#scrollTo=nZ-oiI4YlXGL)\n",
        "\n",
        ">[Connecting to Google Drive](#scrollTo=sqKMRov-lQjI)\n",
        "\n",
        ">[Prepare our dataset](#scrollTo=l-LAEOiUmMgt)\n",
        "\n",
        ">[Model definition and training](#scrollTo=xmoQDAurmSbS)\n",
        "\n",
        ">[Model evaluation](#scrollTo=f53m3bg_p5rk)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nZ-oiI4YlXGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colab ensure we have our own GPU"
      ]
    },
    {
      "metadata": {
        "id": "abWGmIbfhggR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "a83b0a34-da48-4dfb-a7fc-09a43f0c597c"
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/45/99/837428d26b47ebd6b66d6e1b180e98ec4a557767a93a81a02ea9d6242611/GPUtil-1.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
            "Building wheels for collected packages: gputil\n",
            "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/17/0f/04/b79c006972335e35472c0b835ed52bfc0815258d409f560108\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.3.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.6)\n",
            "Collecting humanize\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/e0/e512e4ac6d091fc990bbe13f9e0378f34cf6eecd1c6c268c9e598dcf5bb9/humanize-0.5.1.tar.gz\n",
            "Building wheels for collected packages: humanize\n",
            "  Running setup.py bdist_wheel for humanize ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/69/86/6c/f8b8593bc273ec4b0c653d3827f7482bb2001a2781a73b7f44\n",
            "Successfully built humanize\n",
            "Installing collected packages: humanize\n",
            "Successfully installed humanize-0.5.1\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 139.6 MB\n",
            "GPU RAM Free: 11438MB | Used: 1MB | Util   0% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6U2APHXm65Q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqKMRov-lQjI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Connecting to Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "QiochJEglOwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7fa4f093-2b61-4e81-f1aa-5c9b9af2d0bd"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p my_drive\n",
        "!google-drive-ocamlfuse my_drive\n",
        "!ls my_drive/ai\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "kaggle\tprojects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-LAEOiUmMgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare our dataset"
      ]
    },
    {
      "metadata": {
        "id": "M3yjSJHMh-RR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(451)\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hGW67WZwiBO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "7a234bee-75e4-4ca4-bc73-3994b829c050"
      },
      "cell_type": "code",
      "source": [
        "#gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "x_train_gray = np.dot(x_train[:,:,:,:3], [0.299, 0.587, 0.114])\n",
        "x_test_gray = np.dot(x_test[:,:,:,:3], [0.299, 0.587, 0.114])\n",
        "\n",
        "x_train_gray = x_train_gray.reshape(-1,32,32,1)\n",
        "x_test_gray = x_test_gray.reshape(-1,32,32,1)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "plt.imshow(x_train[1])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(x_train_gray[1,:,:,0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b296b5860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1af891db38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xmoQDAurmSbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model definition and training"
      ]
    },
    {
      "metadata": {
        "id": "KqmcChpEiFJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2205
        },
        "outputId": "fe4ce77e-d156-4f34-8cd7-61cf5b9ceaa6"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(451)\n",
        "\n",
        "import datetime\n",
        "\n",
        "from keras.layers import Flatten, Activation, Conv2D, MaxPool2D, AvgPool2D, Dense, Dropout, BatchNormalization, Input, MaxPooling2D, Flatten, Activation, Conv2D, AvgPool2D, Dense, Dropout, concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from keras.models import model_from_json, Model\n",
        "\n",
        "def build_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                dropout=False, normalization=False, regularization=\"l2\", dropout_ratio=0.25):\n",
        "    #3x3 kernel tower\n",
        "    tower = Conv2D(features_nr, (1,1), padding='same', activation='relu', \n",
        "                     kernel_regularizer=regularization, name='tower_%d_%dx%da'%(tower_nr, shape[0], shape[1]))(input_layer)\n",
        "    tower = Conv2D(features_nr*2, shape, padding='same', activation='relu',\n",
        "                     kernel_regularizer=regularization, name='tower_%d_%dx%db'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "    #condidional dropout/normalization\n",
        "    if dropout:\n",
        "        tower = Dropout(dropout_ratio, name='tower_%d_%dx%ddrop'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "    if normalization:\n",
        "        tower = BatchNormalization(name='tower_%d_%dx%dnorm'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "        \n",
        "    return tower\n",
        "\n",
        "def build_simple_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                dropout=False, normalization=False, regularization=\"l2\", dropout_ratio=0.25):\n",
        "    #3x3 kernel tower\n",
        "    tower = Conv2D(features_nr, shape, padding='same', activation='relu',\n",
        "                     kernel_regularizer=regularization, \n",
        "                   name='tower_simple_%d_%dx%db'%(tower_nr, shape[0], shape[1]))(input_layer)\n",
        "    #condidional dropout/normalization\n",
        "    if dropout:\n",
        "        tower = Dropout(dropout_ratio, name='tower_%d_%dx%ddrop'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "    if normalization:\n",
        "        tower = BatchNormalization(name='tower_%d_%dx%dnorm'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "        \n",
        "    return tower\n",
        "\n",
        "def build_tower_subsample(input_layer, features_nr, shape, tower_nr, \n",
        "                          dropout=False, normalization=False, regularization='l2', dropout_ratio=0.25):\n",
        "    tower = build_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                        dropout, normalization, regularization, dropout_ratio)\n",
        "    pool = MaxPooling2D((2,2), padding='same', name='tower_%d_2x2subsample'%(tower_nr))(tower)\n",
        "\n",
        "    return pool\n",
        "\n",
        "def build_simple_tower_subsample(input_layer, features_nr, shape, tower_nr, \n",
        "                          dropout=False, normalization=False, regularization='l2', dropout_ratio=0.25):\n",
        "    tower = build_simple_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                        dropout, normalization, regularization, dropout_ratio)\n",
        "    pool = MaxPooling2D((2,2), padding='same', name='tower_%d_2x2subsample'%(tower_nr))(tower)\n",
        "\n",
        "    return pool\n",
        "\n",
        "def build_dense(input_layer, neurons_nr, dense_nr, \n",
        "                dropout=False, normalization=False, regularization='l2', dropout_ratio=0.5):\n",
        "    dense = Dense(neurons_nr, kernel_regularizer=regularization, \n",
        "                  name='dense_%d_%d'%(dense_nr, neurons_nr))(input_layer)\n",
        "    \n",
        "    if dropout:\n",
        "        dense = Dropout(dropout_ratio, name='dense_%d_%ddrop'%(dense_nr, neurons_nr))(dense)\n",
        "    if normalization:\n",
        "        dense = BatchNormalization(name='dense_%d_%dnorm'%(dense_nr, neurons_nr))(dense)\n",
        "    \n",
        "    return dense\n",
        "\n",
        "def build_inception_module(input_layer, features_nr, module_nr, \n",
        "                           dropout=False, normalization=False, regularization='l2', dropout_ratio=0.2):  \n",
        "    tower_1 = build_tower(input_layer, features_nr, (3,3), module_nr, \n",
        "                          dropout, normalization, regularization, dropout_ratio)\n",
        "\n",
        "    tower_2 = build_tower(input_layer, features_nr, (5,5), module_nr, \n",
        "                          dropout, normalization, regularization, dropout_ratio)\n",
        "\n",
        "    #max pooling tower\n",
        "    tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same', name='inception_%d_pool3x3a'%(module_nr))(input_layer)\n",
        "    tower_3 = Conv2D(features_nr*2, (1,1), padding='same', activation='relu',\n",
        "                    kernel_regularizer=regularization, name='inception_%d_pool3x3b'%(module_nr))(tower_3)\n",
        "    if dropout:\n",
        "        tower_3 = Dropout(dropout_ratio, name='inception_%d_pool3x3drop'%(module_nr))(tower_3)\n",
        "    if normalization:\n",
        "        tower_3 = BatchNormalization(name='inception_%d_pool3x3norm'%(module_nr))(tower_3)\n",
        "\n",
        "    #concatenate and subsample towers\n",
        "    output = concatenate([tower_1, tower_2, tower_3], axis = 3, name='inception_%d_concat'%(module_nr))\n",
        "\n",
        "    pooled = MaxPooling2D((2,2), padding='same', name='inception_%d_2x2subsample'%(module_nr))(output)\n",
        "    \n",
        "    return pooled\n",
        "\n",
        "i='cifar10-'+datetime.datetime.now().strftime(\"%I:%M%p_%B-%d-%Y\")\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "!mkdir -p models\n",
        "!mkdir -p logs\n",
        "\n",
        "a = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')#will stop the model if val_loss does not improve for 2 consecutive epochs\n",
        "b = ModelCheckpoint(monitor='val_loss', filepath='./models/'+str(i)+'.hdf5', verbose=1, save_best_only=True)#save model weights after each epoch if val_loss improves\n",
        "c = TensorBoard(log_dir='./logs/'+str(i),\n",
        "                write_grads=True,\n",
        "                write_graph=True,\n",
        "                write_images=True,\n",
        "                batch_size=128)#saves a log file for tensorboard; remember to save different runs to different subdirectories\n",
        "\n",
        "#we'll use this instead of decay\n",
        "d = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "\n",
        "callbacks=[a,b,c,d]\n",
        "\n",
        "#------------model definition-------------------\n",
        "\n",
        "use_norm = True\n",
        "lrate = 0.001\n",
        "\n",
        "input_img = Input(shape = (32, 32, 3), name='input')\n",
        "\n",
        "#conv_1 = Conv2D(1, (1,1), padding='same', activation='relu', \n",
        "               # kernel_regularizer = regularization, name='conv_64x64x1_inception_in')(input_img)\n",
        "\n",
        "#hopefully this will learn a good internal representation of the image channels\n",
        "#conv_1 = Conv2D(1, (1,1), padding='same', activation='relu', \n",
        "                #kernel_regularizer = regularization, name='conv_64x64x1_inception_in')(input_img)\n",
        "\n",
        "inception_1 = build_inception_module(input_img, 3, 1, True, use_norm)\n",
        "\n",
        "inception_2 = build_inception_module(inception_1, 36, 2, True, use_norm)\n",
        "\n",
        "inception_3 = build_inception_module(inception_2, 216, 3, True, use_norm)\n",
        "\n",
        "#tower_3 = build_simple_tower(inception_2, 144, (3,3),  3, False, use_norm)\n",
        "#tower_4 = build_simple_tower_subsample(tower_3, 144, (3,3), 4, False, use_norm)\n",
        "\n",
        "tower_5 = build_simple_tower(inception_3, 288, (3,3),  5, False, use_norm)\n",
        "tower_6 = build_simple_tower_subsample(tower_5, 288, (3,3), 6, False, use_norm)\n",
        "\n",
        "#model top\n",
        "\n",
        "flat = Flatten()(tower_6)\n",
        "\n",
        "dense_5 = build_dense(flat, 128, 1, True, use_norm)\n",
        "\n",
        "dense_6 = build_dense(dense_5, 64, 2, True, use_norm)\n",
        "\n",
        "out = Dense(10, activation='softmax')(dense_6)\n",
        "\n",
        "model = Model(inputs = input_img, outputs = out)\n",
        "\n",
        "#-----------------------------------------------\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lrate),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"./models/\"+str(i)+\".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "print(\"Saved model to\" + \"../models/\"+str(i)+\".json\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_3x3a (Conv2D)           (None, 32, 32, 3)    12          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_5x5a (Conv2D)           (None, 32, 32, 3)    12          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_pool3x3a (MaxPoolin (None, 32, 32, 3)    0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_3x3b (Conv2D)           (None, 32, 32, 6)    168         tower_1_3x3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_5x5b (Conv2D)           (None, 32, 32, 6)    456         tower_1_5x5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_pool3x3b (Conv2D)   (None, 32, 32, 6)    24          inception_1_pool3x3a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_3x3drop (Dropout)       (None, 32, 32, 6)    0           tower_1_3x3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_5x5drop (Dropout)       (None, 32, 32, 6)    0           tower_1_5x5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_pool3x3drop (Dropou (None, 32, 32, 6)    0           inception_1_pool3x3b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_3x3norm (BatchNormaliza (None, 32, 32, 6)    24          tower_1_3x3drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tower_1_5x5norm (BatchNormaliza (None, 32, 32, 6)    24          tower_1_5x5drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_pool3x3norm (BatchN (None, 32, 32, 6)    24          inception_1_pool3x3drop[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_concat (Concatenate (None, 32, 32, 18)   0           tower_1_3x3norm[0][0]            \n",
            "                                                                 tower_1_5x5norm[0][0]            \n",
            "                                                                 inception_1_pool3x3norm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_2x2subsample (MaxPo (None, 16, 16, 18)   0           inception_1_concat[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_3x3a (Conv2D)           (None, 16, 16, 36)   684         inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_5x5a (Conv2D)           (None, 16, 16, 36)   684         inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_pool3x3a (MaxPoolin (None, 16, 16, 18)   0           inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_3x3b (Conv2D)           (None, 16, 16, 72)   23400       tower_2_3x3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_5x5b (Conv2D)           (None, 16, 16, 72)   64872       tower_2_5x5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_pool3x3b (Conv2D)   (None, 16, 16, 72)   1368        inception_2_pool3x3a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_3x3drop (Dropout)       (None, 16, 16, 72)   0           tower_2_3x3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_5x5drop (Dropout)       (None, 16, 16, 72)   0           tower_2_5x5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_pool3x3drop (Dropou (None, 16, 16, 72)   0           inception_2_pool3x3b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_3x3norm (BatchNormaliza (None, 16, 16, 72)   288         tower_2_3x3drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tower_2_5x5norm (BatchNormaliza (None, 16, 16, 72)   288         tower_2_5x5drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_pool3x3norm (BatchN (None, 16, 16, 72)   288         inception_2_pool3x3drop[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_concat (Concatenate (None, 16, 16, 216)  0           tower_2_3x3norm[0][0]            \n",
            "                                                                 tower_2_5x5norm[0][0]            \n",
            "                                                                 inception_2_pool3x3norm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_2x2subsample (MaxPo (None, 8, 8, 216)    0           inception_2_concat[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_3x3a (Conv2D)           (None, 8, 8, 216)    46872       inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_5x5a (Conv2D)           (None, 8, 8, 216)    46872       inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_pool3x3a (MaxPoolin (None, 8, 8, 216)    0           inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_3x3b (Conv2D)           (None, 8, 8, 432)    840240      tower_3_3x3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_5x5b (Conv2D)           (None, 8, 8, 432)    2333232     tower_3_5x5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_pool3x3b (Conv2D)   (None, 8, 8, 432)    93744       inception_3_pool3x3a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_3x3drop (Dropout)       (None, 8, 8, 432)    0           tower_3_3x3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_5x5drop (Dropout)       (None, 8, 8, 432)    0           tower_3_5x5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_pool3x3drop (Dropou (None, 8, 8, 432)    0           inception_3_pool3x3b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_3x3norm (BatchNormaliza (None, 8, 8, 432)    1728        tower_3_3x3drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tower_3_5x5norm (BatchNormaliza (None, 8, 8, 432)    1728        tower_3_5x5drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_pool3x3norm (BatchN (None, 8, 8, 432)    1728        inception_3_pool3x3drop[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_concat (Concatenate (None, 8, 8, 1296)   0           tower_3_3x3norm[0][0]            \n",
            "                                                                 tower_3_5x5norm[0][0]            \n",
            "                                                                 inception_3_pool3x3norm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_2x2subsample (MaxPo (None, 4, 4, 1296)   0           inception_3_concat[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tower_simple_5_3x3b (Conv2D)    (None, 4, 4, 288)    3359520     inception_3_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tower_5_3x3norm (BatchNormaliza (None, 4, 4, 288)    1152        tower_simple_5_3x3b[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tower_simple_6_3x3b (Conv2D)    (None, 4, 4, 288)    746784      tower_5_3x3norm[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tower_6_3x3norm (BatchNormaliza (None, 4, 4, 288)    1152        tower_simple_6_3x3b[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tower_6_2x2subsample (MaxPoolin (None, 2, 2, 288)    0           tower_6_3x3norm[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1152)         0           tower_6_2x2subsample[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_128 (Dense)             (None, 128)          147584      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_128drop (Dropout)       (None, 128)          0           dense_1_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_128norm (BatchNormaliza (None, 128)          512         dense_1_128drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_64 (Dense)              (None, 64)           8256        dense_1_128norm[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_64drop (Dropout)        (None, 64)           0           dense_2_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_64norm (BatchNormalizat (None, 64)           256         dense_2_64drop[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         dense_2_64norm[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 7,724,626\n",
            "Trainable params: 7,720,030\n",
            "Non-trainable params: 4,596\n",
            "__________________________________________________________________________________________________\n",
            "Saved model to../models/cifar10-07:25AM_July-07-2018.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZQ5GrZVA1bv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92d7e34d-8a08-4423-85d4-6755a3bb55ac"
      },
      "cell_type": "code",
      "source": [
        "def get_model_memory_usage(batch_size, model):\n",
        "    import numpy as np\n",
        "    from keras import backend as K\n",
        "\n",
        "    shapes_mem_count = 0\n",
        "    for l in model.layers:\n",
        "        single_layer_mem = 1\n",
        "        for s in l.output_shape:\n",
        "            if s is None:\n",
        "                continue\n",
        "            single_layer_mem *= s\n",
        "        shapes_mem_count += single_layer_mem\n",
        "\n",
        "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
        "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
        "\n",
        "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
        "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
        "    return gbytes\n",
        "  \n",
        "print(\"Memory usage (GB):\", get_model_memory_usage(128,model))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage (GB): 4.048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JRZf1eVHiKpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1611
        },
        "outputId": "4f893769-c9a1-49f2-85c2-575469532b6c"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  model.fit(x_train, y_train_cat, batch_size=128, epochs=100, validation_split=0.2,verbose=1,callbacks=callbacks)  # starts training\n",
        "\n",
        "result = model.evaluate(x_test, y_test_cat)\n",
        "\n",
        "print(\"Accuracy on test set: \",result[1]*100,\"%\")\n",
        "\n",
        "#copy our generated model and logs to GoogleDrive\n",
        "!cp -R models my_drive/ai/projects/cifar10\n",
        "!cp -R logs my_drive/ai/projects/cifar10"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 72s 2ms/step - loss: 2.5105 - acc: 0.8954 - val_loss: 0.4420 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.44198, saving model to ./models/cifar10-07:25AM_July-07-2018.hdf5\n",
            "Epoch 2/100\n",
            "17280/40000 [===========>..................] - ETA: 34s - loss: 0.3564 - acc: 0.8995"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 64s 2ms/step - loss: 0.3385 - acc: 0.9004 - val_loss: 0.4282 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.44198 to 0.42820, saving model to ./models/cifar10-07:25AM_July-07-2018.hdf5\n",
            "Epoch 3/100\n",
            "31488/40000 [======================>.......] - ETA: 12s - loss: 0.3076 - acc: 0.9038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 64s 2ms/step - loss: 0.3050 - acc: 0.9040 - val_loss: 0.3714 - val_acc: 0.9016\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.42820 to 0.37139, saving model to ./models/cifar10-07:25AM_July-07-2018.hdf5\n",
            "Epoch 4/100\n",
            "19072/40000 [=============>................] - ETA: 31s - loss: 0.2961 - acc: 0.9055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7d103687dd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# starts training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "f53m3bg_p5rk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "TqgxBsf7j3lD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5d92ac3d-8515-4f20-c1f1-52ca07178897"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('./models/cifar10-06:43AM_July-07-2018.hdf5')\n",
        "\n",
        "result = model.evaluate(x_test, y_test_cat)\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 6s 578us/step\n",
            "[0.20430024523735046, 0.9331499870300293]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}