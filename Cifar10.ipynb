{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Tzeny/cifar10/blob/master/Cifar10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "509BEESjqAt5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is my attempt at solving the Cifar10 challenge. This file is also available on GitHub: [https://github.com/Tzeny/cifar10/blob/master/Cifar10.ipynb](https://github.com/Tzeny/cifar10/blob/master/Cifar10.ipynb)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZU99-wAUrBei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "|Nr. crt.|Model architecture | Optimizer | Batch size  | Train images | Stop epoch | Test accuracy |\n",
        "|---||------------- |---|-------------|----|\n",
        "|1|2 x inception(w dr 3,36) 2 x (conv(144ft)+maxpool) flt 2 x dense (w dr) act \\[w batch normalization\\]|Adam(0.001)|128|Normalized color |~20|~93 %\n",
        "|2|3 x inception(w dr 3, 36,216) (conv(288ft)+maxpool) flt 2 x dense (w dr) \\[w batch normalization\\]|Adam(0.001)|128|Normalized color|31|~91.11 %\n",
        "|3|2 x inception(w dr 3,36) 2 x (conv(144ft)+maxpool) flt 2 x dense (w dr) act \\[w batch normalization\\]|Adam(0.001)|128|Normalized color |32|92.58 %\n",
        "|5|3 x inception(w 3,36, GoogLeNet feature cnt) flt 2 x dense (w dr) act \\[w batch normalization\\]|Adam(0.001)|128|Normalized color |31|96.93 %"
      ]
    },
    {
      "metadata": {
        "id": "mIYeok5Dp-YC",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[Google Colab ensure we have our own GPU](#scrollTo=nZ-oiI4YlXGL)\n",
        "\n",
        ">[Connecting to Google Drive](#scrollTo=sqKMRov-lQjI)\n",
        "\n",
        ">[Prepare our dataset](#scrollTo=l-LAEOiUmMgt)\n",
        "\n",
        ">[Model definition and training](#scrollTo=xmoQDAurmSbS)\n",
        "\n",
        ">[Model evaluation](#scrollTo=f53m3bg_p5rk)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nZ-oiI4YlXGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colab ensure we have our own GPU"
      ]
    },
    {
      "metadata": {
        "id": "abWGmIbfhggR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "4e526ca6-fa58-4d1f-e9da-45560c3713e7"
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/45/99/837428d26b47ebd6b66d6e1b180e98ec4a557767a93a81a02ea9d6242611/GPUtil-1.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
            "Building wheels for collected packages: gputil\n",
            "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/17/0f/04/b79c006972335e35472c0b835ed52bfc0815258d409f560108\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.3.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.6)\n",
            "Collecting humanize\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/e0/e512e4ac6d091fc990bbe13f9e0378f34cf6eecd1c6c268c9e598dcf5bb9/humanize-0.5.1.tar.gz\n",
            "Building wheels for collected packages: humanize\n",
            "  Running setup.py bdist_wheel for humanize ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/69/86/6c/f8b8593bc273ec4b0c653d3827f7482bb2001a2781a73b7f44\n",
            "Successfully built humanize\n",
            "Installing collected packages: humanize\n",
            "Successfully installed humanize-0.5.1\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 139.5 MB\n",
            "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6U2APHXm65Q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqKMRov-lQjI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Connecting to Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "QiochJEglOwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "8ba957e8-a956-4cff-dd9e-ed4b166e583e"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p my_drive\n",
        "!google-drive-ocamlfuse my_drive\n",
        "!ls my_drive/ai\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmp88mi_mqq/pubring.gpg' created\n",
            "gpg: /tmp/tmp88mi_mqq/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19804 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "kaggle\tprojects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-LAEOiUmMgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare our dataset"
      ]
    },
    {
      "metadata": {
        "id": "M3yjSJHMh-RR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8f5bf3be-50c2-4f1a-c791-4edd5eeb8ef1"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(451)\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hGW67WZwiBO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "d5ddf05b-dee7-4425-887c-f4fb7291a0a7"
      },
      "cell_type": "code",
      "source": [
        "#gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "x_train_gray = np.dot(x_train[:,:,:,:3], [0.299, 0.587, 0.114])\n",
        "x_test_gray = np.dot(x_test[:,:,:,:3], [0.299, 0.587, 0.114])\n",
        "\n",
        "x_train_gray = x_train_gray.reshape(-1,32,32,1)\n",
        "x_test_gray = x_test_gray.reshape(-1,32,32,1)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "plt.imshow(x_train[1])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(x_train_gray[1,:,:,0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd66d73bf28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd66d6e4f28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xmoQDAurmSbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model definition and training"
      ]
    },
    {
      "metadata": {
        "id": "KqmcChpEiFJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2086
        },
        "outputId": "c88d6cb1-d167-43be-a00e-4d4cd3680b66"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(451)\n",
        "\n",
        "import datetime\n",
        "\n",
        "from keras.layers import Flatten, Activation, Conv2D, MaxPool2D, AvgPool2D, Dense, Dropout, BatchNormalization, Input, MaxPooling2D, Flatten, Activation, Conv2D, AvgPool2D, Dense, Dropout, concatenate, AveragePooling2D\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Sequential\n",
        "import keras.backend as K\n",
        "from keras.regularizers import l1,l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from keras.models import model_from_json, Model\n",
        "\n",
        "def build_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                dropout=False, normalization=False, regularization=\"l2\", dropout_ratio=0.25):\n",
        "    #3x3 kernel tower\n",
        "    tower = Conv2D(features_nr, (1,1), padding='same', activation='relu', \n",
        "                     kernel_regularizer=regularization, name='tower_%d_%dx%da'%(tower_nr, shape[0], shape[1]))(input_layer)\n",
        "    tower = Conv2D(features_nr*2, shape, padding='same', activation='relu',\n",
        "                     kernel_regularizer=regularization, name='tower_%d_%dx%db'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "    #condidional dropout/normalization\n",
        "    if dropout:\n",
        "        tower = Dropout(dropout_ratio, name='tower_%d_%dx%ddrop'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "    if normalization:\n",
        "        tower = BatchNormalization(name='tower_%d_%dx%dnorm'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "        \n",
        "    return tower\n",
        "\n",
        "def build_simple_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                dropout=False, normalization=False, regularization=\"l2\", dropout_ratio=0.25):\n",
        "    #3x3 kernel tower\n",
        "    tower = Conv2D(features_nr, shape, padding='same', activation='relu',\n",
        "                     kernel_regularizer=regularization, \n",
        "                   name='tower_simple_%d_%dx%db'%(tower_nr, shape[0], shape[1]))(input_layer)\n",
        "    #condidional dropout/normalization\n",
        "    if dropout:\n",
        "        tower = Dropout(dropout_ratio, name='tower_%d_%dx%ddrop'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "    if normalization:\n",
        "        tower = BatchNormalization(name='tower_%d_%dx%dnorm'%(tower_nr, shape[0], shape[1]))(tower)\n",
        "        \n",
        "    return tower\n",
        "\n",
        "def build_tower_subsample(input_layer, features_nr, shape, tower_nr, \n",
        "                          dropout=False, normalization=False, regularization='l2', dropout_ratio=0.25):\n",
        "    tower = build_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                        dropout, normalization, regularization, dropout_ratio)\n",
        "    pool = MaxPooling2D((2,2), padding='same', name='tower_%d_2x2subsample'%(tower_nr))(tower)\n",
        "\n",
        "    return pool\n",
        "\n",
        "def build_simple_tower_subsample(input_layer, features_nr, shape, tower_nr, \n",
        "                          dropout=False, normalization=False, regularization='l2', dropout_ratio=0.25):\n",
        "    tower = build_simple_tower(input_layer, features_nr, shape, tower_nr, \n",
        "                        dropout, normalization, regularization, dropout_ratio)\n",
        "    pool = MaxPooling2D((2,2), padding='same', name='tower_%d_2x2subsample'%(tower_nr))(tower)\n",
        "\n",
        "    return pool\n",
        "\n",
        "def build_dense(input_layer, neurons_nr, dense_nr, \n",
        "                dropout=False, normalization=False, regularization='l2', dropout_ratio=0.5):\n",
        "    dense = Dense(neurons_nr, kernel_regularizer=regularization, \n",
        "                  name='dense_%d_%d'%(dense_nr, neurons_nr))(input_layer)\n",
        "    \n",
        "    if dropout:\n",
        "        dense = Dropout(dropout_ratio, name='dense_%d_%ddrop'%(dense_nr, neurons_nr))(dense)\n",
        "    if normalization:\n",
        "        dense = BatchNormalization(name='dense_%d_%dnorm'%(dense_nr, neurons_nr))(dense)\n",
        "    \n",
        "    return dense\n",
        "\n",
        "def build_inception_module(input_layer, features_nr, module_nr, \n",
        "                           dropout=False, normalization=False, regularization='l2', dropout_ratio=0.2):  \n",
        "    #feature_nr is an array we'll use to build our layers\n",
        "    #data is in the form: [1x1, 3x3 reduce, 3x3, 5x5 reduce, 5x5, pool proj]\n",
        "  \n",
        "    inception_1x1 = Conv2D(features_nr[0],1,1,border_mode='same',activation='relu',name='inception_%d_/1x1'%(module_nr),W_regularizer=l2(0.0002))(input_layer)\n",
        "    \n",
        "    inception_3x3_reduce = Conv2D(features_nr[1],1,1,border_mode='same',activation='relu',name='inception_%d_/3x3_reduce'%(module_nr),W_regularizer=l2(0.0002))(input_layer)\n",
        "    \n",
        "    inception_3x3 = Conv2D(features_nr[2],3,3,border_mode='same',activation='relu',name='inception_%d_/3x3'%(module_nr),W_regularizer=l2(0.0002))(inception_3x3_reduce)\n",
        "    \n",
        "    inception_5x5_reduce = Conv2D(features_nr[3],1,1,border_mode='same',activation='relu',name='inception_%d_/5x5_reduce'%(module_nr),W_regularizer=l2(0.0002))(input_layer)\n",
        "    \n",
        "    inception_5x5 = Conv2D(features_nr[4],5,5,border_mode='same',activation='relu',name='inception_%d_/5x5'%(module_nr),W_regularizer=l2(0.0002))(inception_5x5_reduce)\n",
        "    \n",
        "    inception_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_%d_/pool'%(module_nr))(input_layer)\n",
        "    \n",
        "    inception_pool_proj = Conv2D(features_nr[5],1,1,border_mode='same',activation='relu',name='inception_%d_/pool_proj'%(module_nr),W_regularizer=l2(0.0002))(inception_pool)\n",
        "    \n",
        "    inception_output = concatenate([inception_1x1,inception_3x3,inception_5x5,inception_pool_proj],axis=3,name='inception_%d_/output'%(module_nr))\n",
        "\n",
        "    if dropout:\n",
        "        inception_output = Dropout(dropout_ratio, name='inception_%d_/output_drop'%(module_nr))(inception_output)\n",
        "    if normalization:\n",
        "        inception_output = BatchNormalization(name='inception_%d_/output_norm'%(module_nr))(inception_output)\n",
        "\n",
        "    pooled = MaxPooling2D((2,2), padding='same', name='inception_%d_2x2subsample'%(module_nr))(inception_output)\n",
        "    \n",
        "    return pooled\n",
        "\n",
        "i='cifar10-nrcrt6-'+datetime.datetime.now().strftime(\"%I:%M%p_%B-%d-%Y\")\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "!mkdir -p models\n",
        "!mkdir -p logs\n",
        "\n",
        "a = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')#will stop the model if val_loss does not improve for 2 consecutive epochs\n",
        "b = ModelCheckpoint(monitor='val_loss', filepath='./models/'+str(i)+'.hdf5', verbose=1, save_best_only=True)#save model weights after each epoch if val_loss improves\n",
        "c = TensorBoard(log_dir='./logs/'+str(i),\n",
        "                write_grads=True,\n",
        "                write_graph=True,\n",
        "                write_images=True,\n",
        "                batch_size=128)#saves a log file for tensorboard; remember to save different runs to different subdirectories\n",
        "\n",
        "#we'll use this instead of decay\n",
        "d = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "\n",
        "callbacks=[a,b,c,d]\n",
        "\n",
        "#------------model definition-------------------\n",
        "\n",
        "use_norm = True\n",
        "lrate = 0.001\n",
        "\n",
        "input_img = Input(shape = (32, 32, 3), name='input')\n",
        "\n",
        "#conv_1 = Conv2D(1, (1,1), padding='same', activation='relu', \n",
        "               # kernel_regularizer = regularization, name='conv_64x64x1_inception_in')(input_img)\n",
        "\n",
        "#hopefully this will learn a good internal representation of the image channels\n",
        "#conv_1 = Conv2D(1, (1,1), padding='same', activation='relu', \n",
        "                #kernel_regularizer = regularization, name='conv_64x64x1_inception_in')(input_img)\n",
        "\n",
        "inception_1 = build_inception_module(input_img, [64,96,128,16,32,32], 1, False, use_norm)\n",
        "\n",
        "inception_2 = build_inception_module(inception_1, [128,128,192,32,96,64], 2, False, use_norm)\n",
        "\n",
        "inception_3 = build_inception_module(inception_2, [192,96,208,16,48,64], 3, False, use_norm)\n",
        "#tower_3 = build_simple_tower(inception_2, 144, (3,3),  3, False, use_norm)\n",
        "#tower_4 = build_simple_tower_subsample(tower_3, 144, (3,3), 4, False, use_norm)\n",
        "\n",
        "#tower_5 = build_simple_tower(tower_4, 288, (3,3),  5, False, use_norm)\n",
        "#tower_6 = build_simple_tower_subsample(tower_5, 288, (3,3), 6, False, use_norm)\n",
        "\n",
        "#model top\n",
        "\n",
        "flat_pool = AveragePooling2D(pool_size=(4, 4), padding='valid')(inception_3)\n",
        "\n",
        "flat = Flatten()(flat_pool)\n",
        "\n",
        "\n",
        "dense_5 = build_dense(flat, 128, 1, True, use_norm)\n",
        "\n",
        "dense_6 = build_dense(dense_5, 64, 2, True, use_norm)\n",
        "\n",
        "out = Dense(10, activation='softmax')(dense_6)\n",
        "\n",
        "model = Model(inputs = input_img, outputs = out)\n",
        "\n",
        "#-----------------------------------------------\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lrate),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"./models/\"+str(i)+\".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "print(\"Saved model to\" + \"../models/\"+str(i)+\".json\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_1_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), activation=\"relu\", name=\"inception_1_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"inception_1_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", name=\"inception_1_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", name=\"inception_1_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_1_/pool\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_1_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_2_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_2_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", name=\"inception_2_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_2_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (5, 5), activation=\"relu\", name=\"inception_2_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_2_/pool\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_2_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", name=\"inception_3_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), activation=\"relu\", name=\"inception_3_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(208, (3, 3), activation=\"relu\", name=\"inception_3_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", name=\"inception_3_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", name=\"inception_3_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_3_/pool\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_3_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/3x3_reduce (Conv2D (None, 32, 32, 96)   384         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/5x5_reduce (Conv2D (None, 32, 32, 16)   64          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/pool (MaxPooling2D (None, 32, 32, 3)    0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/1x1 (Conv2D)       (None, 32, 32, 64)   256         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/3x3 (Conv2D)       (None, 32, 32, 128)  110720      inception_1_/3x3_reduce[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/5x5 (Conv2D)       (None, 32, 32, 32)   12832       inception_1_/5x5_reduce[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/pool_proj (Conv2D) (None, 32, 32, 32)   128         inception_1_/pool[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/output (Concatenat (None, 32, 32, 256)  0           inception_1_/1x1[0][0]           \n",
            "                                                                 inception_1_/3x3[0][0]           \n",
            "                                                                 inception_1_/5x5[0][0]           \n",
            "                                                                 inception_1_/pool_proj[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_/output_norm (Batch (None, 32, 32, 256)  1024        inception_1_/output[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "inception_1_2x2subsample (MaxPo (None, 16, 16, 256)  0           inception_1_/output_norm[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/3x3_reduce (Conv2D (None, 16, 16, 128)  32896       inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/5x5_reduce (Conv2D (None, 16, 16, 32)   8224        inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/pool (MaxPooling2D (None, 16, 16, 256)  0           inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/1x1 (Conv2D)       (None, 16, 16, 128)  32896       inception_1_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/3x3 (Conv2D)       (None, 16, 16, 192)  221376      inception_2_/3x3_reduce[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/5x5 (Conv2D)       (None, 16, 16, 96)   76896       inception_2_/5x5_reduce[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/pool_proj (Conv2D) (None, 16, 16, 64)   16448       inception_2_/pool[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/output (Concatenat (None, 16, 16, 480)  0           inception_2_/1x1[0][0]           \n",
            "                                                                 inception_2_/3x3[0][0]           \n",
            "                                                                 inception_2_/5x5[0][0]           \n",
            "                                                                 inception_2_/pool_proj[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_/output_norm (Batch (None, 16, 16, 480)  1920        inception_2_/output[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "inception_2_2x2subsample (MaxPo (None, 8, 8, 480)    0           inception_2_/output_norm[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/3x3_reduce (Conv2D (None, 8, 8, 96)     46176       inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/5x5_reduce (Conv2D (None, 8, 8, 16)     7696        inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/pool (MaxPooling2D (None, 8, 8, 480)    0           inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/1x1 (Conv2D)       (None, 8, 8, 192)    92352       inception_2_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/3x3 (Conv2D)       (None, 8, 8, 208)    179920      inception_3_/3x3_reduce[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/5x5 (Conv2D)       (None, 8, 8, 48)     19248       inception_3_/5x5_reduce[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/pool_proj (Conv2D) (None, 8, 8, 64)     30784       inception_3_/pool[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/output (Concatenat (None, 8, 8, 512)    0           inception_3_/1x1[0][0]           \n",
            "                                                                 inception_3_/3x3[0][0]           \n",
            "                                                                 inception_3_/5x5[0][0]           \n",
            "                                                                 inception_3_/pool_proj[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_/output_norm (Batch (None, 8, 8, 512)    2048        inception_3_/output[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "inception_3_2x2subsample (MaxPo (None, 4, 4, 512)    0           inception_3_/output_norm[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           inception_3_2x2subsample[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_128 (Dense)             (None, 128)          65664       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_128drop (Dropout)       (None, 128)          0           dense_1_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_128norm (BatchNormaliza (None, 128)          512         dense_1_128drop[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_64 (Dense)              (None, 64)           8256        dense_1_128norm[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_64drop (Dropout)        (None, 64)           0           dense_2_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_64norm (BatchNormalizat (None, 64)           256         dense_2_64drop[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         dense_2_64norm[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 969,626\n",
            "Trainable params: 966,746\n",
            "Non-trainable params: 2,880\n",
            "__________________________________________________________________________________________________\n",
            "Saved model to../models/cifar10-nrcrt5-06:35AM_July-11-2018.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZQ5GrZVA1bv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdfbb441-5918-43b1-b963-d141e8adfece"
      },
      "cell_type": "code",
      "source": [
        "def get_model_memory_usage(batch_size, model):\n",
        "    import numpy as np\n",
        "    from keras import backend as K\n",
        "\n",
        "    shapes_mem_count = 0\n",
        "    for l in model.layers:\n",
        "        single_layer_mem = 1\n",
        "        for s in l.output_shape:\n",
        "            if s is None:\n",
        "                continue\n",
        "            single_layer_mem *= s\n",
        "        shapes_mem_count += single_layer_mem\n",
        "\n",
        "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
        "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
        "\n",
        "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
        "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
        "    return gbytes\n",
        "  \n",
        "print(\"Memory usage (GB):\", get_model_memory_usage(128,model))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage (GB): 1.237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JRZf1eVHiKpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2277
        },
        "outputId": "76a2cfba-4393-44f2-da13-e2f9c0e27e0a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  model.fit(x_train, y_train_cat, batch_size=128, epochs=100, validation_split=0.2,verbose=1,callbacks=callbacks)  # starts training\n",
        "\n",
        "result = model.evaluate(x_test, y_test_cat)\n",
        "\n",
        "print(\"Accuracy on test set: \",result[1]*100,\"%\")\n",
        "\n",
        "#copy our generated model and logs to GoogleDrive\n",
        "!cp -R models my_drive/ai/projects/cifar10\n",
        "!cp -R logs my_drive/ai/projects/cifar10\n",
        "\n",
        "print(\"Copied model and logs to Google Drive\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 73s 2ms/step - loss: 0.8715 - acc: 0.9053 - val_loss: 0.3898 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.38979, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 2/100\n",
            "13440/40000 [=========>....................] - ETA: 42s - loss: 0.3199 - acc: 0.9235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.2907 - acc: 0.9272 - val_loss: 0.3650 - val_acc: 0.9056\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.38979 to 0.36498, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 3/100\n",
            "25984/40000 [==================>...........] - ETA: 22s - loss: 0.2443 - acc: 0.9364"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.2411 - acc: 0.9370 - val_loss: 0.2978 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.36498 to 0.29782, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 4/100\n",
            "29312/40000 [====================>.........] - ETA: 16s - loss: 0.2202 - acc: 0.9420"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.2192 - acc: 0.9422 - val_loss: 0.2565 - val_acc: 0.9267\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.29782 to 0.25653, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 5/100\n",
            "30208/40000 [=====================>........] - ETA: 15s - loss: 0.2046 - acc: 0.9467"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.2056 - acc: 0.9464 - val_loss: 0.2707 - val_acc: 0.9276\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.25653\n",
            "Epoch 6/100\n",
            "37120/40000 [==========================>...] - ETA: 4s - loss: 0.1969 - acc: 0.9497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1966 - acc: 0.9498 - val_loss: 0.4357 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.25653\n",
            "Epoch 7/100\n",
            "39168/40000 [============================>.] - ETA: 1s - loss: 0.1895 - acc: 0.9529"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1896 - acc: 0.9528 - val_loss: 0.2241 - val_acc: 0.9379\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.25653 to 0.22405, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 8/100\n",
            "31104/40000 [======================>.......] - ETA: 14s - loss: 0.1826 - acc: 0.9547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1826 - acc: 0.9546 - val_loss: 0.2131 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.22405 to 0.21315, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 9/100\n",
            "28928/40000 [====================>.........] - ETA: 17s - loss: 0.1746 - acc: 0.9584"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1755 - acc: 0.9578 - val_loss: 0.2915 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.21315\n",
            "Epoch 10/100\n",
            "34944/40000 [=========================>....] - ETA: 7s - loss: 0.1701 - acc: 0.9598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1709 - acc: 0.9596 - val_loss: 0.2710 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.21315\n",
            "Epoch 11/100\n",
            "38656/40000 [===========================>..] - ETA: 2s - loss: 0.1689 - acc: 0.9599"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1690 - acc: 0.9599 - val_loss: 0.2003 - val_acc: 0.9491\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.21315 to 0.20027, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 12/100\n",
            "32000/40000 [=======================>......] - ETA: 12s - loss: 0.1650 - acc: 0.9617"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1649 - acc: 0.9616 - val_loss: 0.1748 - val_acc: 0.9570\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.20027 to 0.17482, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 13/100\n",
            "27904/40000 [===================>..........] - ETA: 19s - loss: 0.1588 - acc: 0.9638"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1599 - acc: 0.9635 - val_loss: 0.1975 - val_acc: 0.9468\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.17482\n",
            "Epoch 14/100\n",
            "33152/40000 [=======================>......] - ETA: 10s - loss: 0.1565 - acc: 0.9647"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1576 - acc: 0.9644 - val_loss: 0.2465 - val_acc: 0.9344\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.17482\n",
            "Epoch 15/100\n",
            "37504/40000 [===========================>..] - ETA: 3s - loss: 0.1555 - acc: 0.9654"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1559 - acc: 0.9652 - val_loss: 0.1816 - val_acc: 0.9570\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.17482\n",
            "Epoch 16/100\n",
            "35840/40000 [=========================>....] - ETA: 6s - loss: 0.1539 - acc: 0.9661"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1540 - acc: 0.9660 - val_loss: 0.2039 - val_acc: 0.9476\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.17482\n",
            "Epoch 17/100\n",
            "36736/40000 [==========================>...] - ETA: 5s - loss: 0.1499 - acc: 0.9672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1508 - acc: 0.9669 - val_loss: 0.2528 - val_acc: 0.9338\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.17482\n",
            "Epoch 18/100\n",
            "36480/40000 [==========================>...] - ETA: 5s - loss: 0.1226 - acc: 0.9769"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1218 - acc: 0.9771 - val_loss: 0.1375 - val_acc: 0.9686\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.17482 to 0.13747, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 19/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.1039 - acc: 0.9815 - val_loss: 0.1327 - val_acc: 0.9685\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.13747 to 0.13273, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 20/100\n",
            "27776/40000 [===================>..........] - ETA: 19s - loss: 0.0941 - acc: 0.9840"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0938 - acc: 0.9839 - val_loss: 0.1288 - val_acc: 0.9692\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.13273 to 0.12875, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 21/100\n",
            "27648/40000 [===================>..........] - ETA: 19s - loss: 0.0864 - acc: 0.9858"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0862 - acc: 0.9856 - val_loss: 0.1271 - val_acc: 0.9686\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.12875 to 0.12707, saving model to ./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5\n",
            "Epoch 22/100\n",
            "27008/40000 [===================>..........] - ETA: 20s - loss: 0.0810 - acc: 0.9868"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0807 - acc: 0.9869 - val_loss: 0.1273 - val_acc: 0.9683\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.12707\n",
            "Epoch 23/100\n",
            "32768/40000 [=======================>......] - ETA: 11s - loss: 0.0757 - acc: 0.9886"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0755 - acc: 0.9885 - val_loss: 0.1305 - val_acc: 0.9676\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.12707\n",
            "Epoch 24/100\n",
            "35584/40000 [=========================>....] - ETA: 6s - loss: 0.0711 - acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0712 - acc: 0.9898 - val_loss: 0.1341 - val_acc: 0.9667\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.12707\n",
            "Epoch 25/100\n",
            "38400/40000 [===========================>..] - ETA: 2s - loss: 0.0660 - acc: 0.9916"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0660 - acc: 0.9915 - val_loss: 0.1325 - val_acc: 0.9679\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.12707\n",
            "Epoch 26/100\n",
            "38400/40000 [===========================>..] - ETA: 2s - loss: 0.0625 - acc: 0.9925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0625 - acc: 0.9925 - val_loss: 0.1329 - val_acc: 0.9676\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.12707\n",
            "Epoch 27/100\n",
            "38784/40000 [============================>.] - ETA: 1s - loss: 0.0571 - acc: 0.9946"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0572 - acc: 0.9945 - val_loss: 0.1316 - val_acc: 0.9681\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.12707\n",
            "Epoch 28/100\n",
            "39296/40000 [============================>.] - ETA: 1s - loss: 0.0558 - acc: 0.9950"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0558 - acc: 0.9951 - val_loss: 0.1321 - val_acc: 0.9682\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.12707\n",
            "Epoch 29/100\n",
            "38272/40000 [===========================>..] - ETA: 2s - loss: 0.0551 - acc: 0.9952\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0551 - acc: 0.9952 - val_loss: 0.1325 - val_acc: 0.9682\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.12707\n",
            "Epoch 30/100\n",
            "37376/40000 [===========================>..] - ETA: 4s - loss: 0.0541 - acc: 0.9956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0542 - acc: 0.9955 - val_loss: 0.1330 - val_acc: 0.9682\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.12707\n",
            "Epoch 31/100\n",
            "37632/40000 [===========================>..] - ETA: 3s - loss: 0.0533 - acc: 0.9958"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0532 - acc: 0.9958 - val_loss: 0.1340 - val_acc: 0.9679\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.12707\n",
            "Epoch 00031: early stopping\n",
            "10000/10000 [==============================] - 8s 843us/step\n",
            "Accuracy on test set:  96.7410002708435 %\n",
            "Copied model and logs to Google Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f53m3bg_p5rk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "TqgxBsf7j3lD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1658faa7-78ae-4bf9-93f2-9bdefd7b6bb1"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('./models/cifar10-nrcrt5-06:35AM_July-11-2018.hdf5')\n",
        "\n",
        "result = model.evaluate(x_test, y_test_cat)\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 8s 825us/step\n",
            "[0.12818889632225036, 0.9693300001144409]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}